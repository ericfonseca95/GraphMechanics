{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "badf02ff",
   "metadata": {},
   "source": [
    "# GraphMechanics Development Testing\n",
    "\n",
    "This notebook tests the complete GraphMechanics package functionality after fixing the graph_builder.py file.\n",
    "\n",
    "## Test Plan:\n",
    "1. Import all package components\n",
    "2. Load and parse motion capture data\n",
    "3. Build graphs from motion data\n",
    "4. Test GraphTransformer model\n",
    "5. Run complete pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a10e0825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:53:32) [GCC 12.3.0]\n",
      "PyTorch version: 2.7.1+cu126\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/funsega/GraphMechanics')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d397098",
   "metadata": {},
   "source": [
    "## 1. Test Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee982d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ TRCParser import successful\n",
      "âœ“ Graph builder components import successful\n",
      "âœ“ GraphTransformer import successful\n",
      "âœ— MotionTrainer import failed: No module named 'graphmechanics.training.trainer'\n"
     ]
    }
   ],
   "source": [
    "# Test importing all GraphMechanics components\n",
    "try:\n",
    "    from graphmechanics.utils.trc_parser import TRCParser\n",
    "    print(\"âœ“ TRCParser import successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— TRCParser import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from graphmechanics.data.graph_builder import MotionGraphConverter, KinematicGraphBuilder, create_motion_graph\n",
    "    print(\"âœ“ Graph builder components import successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— Graph builder import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from graphmechanics.models.graph_transformer import GraphTransformer\n",
    "    print(\"âœ“ GraphTransformer import successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— GraphTransformer import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from graphmechanics.training.trainer import MotionTrainer\n",
    "    print(\"âœ“ MotionTrainer import successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— MotionTrainer import failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2791f131",
   "metadata": {},
   "source": [
    "## 2. Load Motion Capture Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e44b048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRC file not found: /home/funsega/jump.trc\n"
     ]
    }
   ],
   "source": [
    "# Test loading the jump.trc file\n",
    "trc_file = \"/home/funsega/jump.trc\"\n",
    "\n",
    "if os.path.exists(trc_file):\n",
    "    print(f\"Loading TRC file: {trc_file}\")\n",
    "    \n",
    "    parser = TRCParser()\n",
    "    trc_data = parser.parse_file(trc_file)\n",
    "    \n",
    "    print(f\"\\nTRC Data Summary:\")\n",
    "    print(f\"- Frames: {len(trc_data['positions'])}\")\n",
    "    print(f\"- Frame rate: {trc_data['frame_rate']} Hz\")\n",
    "    print(f\"- Duration: {len(trc_data['positions']) / trc_data['frame_rate']:.2f} seconds\")\n",
    "    print(f\"- Markers: {len(trc_data['joint_names'])}\")\n",
    "    \n",
    "    print(f\"\\nFirst 10 marker names:\")\n",
    "    for i, name in enumerate(trc_data['joint_names'][:10]):\n",
    "        print(f\"  {i+1:2d}. {name}\")\n",
    "    \n",
    "    if len(trc_data['joint_names']) > 10:\n",
    "        print(f\"  ... and {len(trc_data['joint_names']) - 10} more markers\")\n",
    "        \n",
    "else:\n",
    "    print(f\"TRC file not found: {trc_file}\")\n",
    "    trc_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb669593",
   "metadata": {},
   "source": [
    "## 3. Test MotionGraphConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "665eb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trc_data is not None:\n",
    "    print(\"Testing MotionGraphConverter...\")\n",
    "    \n",
    "    # Initialize converter\n",
    "    converter = MotionGraphConverter()\n",
    "    \n",
    "    # Test kinematic feature computation\n",
    "    positions = trc_data['positions']\n",
    "    print(f\"Position data shape: {positions.shape}\")\n",
    "    \n",
    "    features = converter.compute_kinematic_features(positions, dt=1/trc_data['frame_rate'])\n",
    "    print(f\"Kinematic features shape: {features.shape}\")\n",
    "    print(f\"Features include: position (x,y,z) + velocity (vx,vy,vz) = 6 features per joint\")\n",
    "    \n",
    "    # Test edge index creation\n",
    "    edge_index = converter.create_edge_index(trc_data['joint_names'])\n",
    "    print(f\"\\nEdge index shape: {edge_index.shape}\")\n",
    "    print(f\"Number of edges: {edge_index.shape[1]}\")\n",
    "    \n",
    "    # Convert to PyG data objects\n",
    "    print(\"\\nConverting to PyTorch Geometric data objects...\")\n",
    "    data_objects = converter.trc_to_pyg_data(trc_data, frame_window=10)\n",
    "    \n",
    "    print(f\"Generated {len(data_objects)} graph data objects\")\n",
    "    \n",
    "    if data_objects:\n",
    "        sample_data = data_objects[0]\n",
    "        print(f\"\\nSample data object:\")\n",
    "        print(f\"- Node features shape: {sample_data.x.shape}\")\n",
    "        print(f\"- Edge index shape: {sample_data.edge_index.shape}\")\n",
    "        print(f\"- Number of nodes: {sample_data.num_nodes}\")\n",
    "        print(f\"- Frame range: {sample_data.frame_start} to {sample_data.frame_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccb40c1",
   "metadata": {},
   "source": [
    "## 4. Test KinematicGraphBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cd8e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trc_data is not None:\n",
    "    print(\"Testing KinematicGraphBuilder...\")\n",
    "    \n",
    "    # Initialize graph builder\n",
    "    graph_builder = KinematicGraphBuilder(connectivity_type='skeletal')\n",
    "    \n",
    "    # Test edge index building\n",
    "    edge_index = graph_builder.build_edge_index(trc_data['joint_names'])\n",
    "    print(f\"Edge index shape: {edge_index.shape}\")\n",
    "    \n",
    "    # Test with subset of markers (if available)\n",
    "    common_markers = ['RHip', 'LHip', 'RKnee', 'LKnee', 'RAnkle', 'LAnkle']\n",
    "    available_markers = [m for m in common_markers if m in trc_data['joint_names']]\n",
    "    \n",
    "    if available_markers:\n",
    "        print(f\"\\nTesting with common markers: {available_markers}\")\n",
    "        subset_edge_index = graph_builder.build_edge_index(available_markers)\n",
    "        print(f\"Subset edge index shape: {subset_edge_index.shape}\")\n",
    "        \n",
    "        # Create dummy node features for edge weight computation\n",
    "        dummy_features = torch.randn(len(available_markers), 6)  # 6 features per node\n",
    "        edge_weights = graph_builder.compute_edge_weights(\n",
    "            dummy_features, subset_edge_index, weight_type='distance'\n",
    "        )\n",
    "        print(f\"Edge weights shape: {edge_weights.shape}\")\n",
    "        print(f\"Edge weights range: {edge_weights.min():.3f} to {edge_weights.max():.3f}\")\n",
    "    else:\n",
    "        print(\"No common skeletal markers found for subset testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca633c",
   "metadata": {},
   "source": [
    "## 5. Test GraphTransformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8d95e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_objects' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdata_objects\u001b[49m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTesting GraphTransformer model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Get dimensions from sample data\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'data_objects' is not defined"
     ]
    }
   ],
   "source": [
    "if data_objects:\n",
    "    print(\"Testing GraphTransformer model...\")\n",
    "    \n",
    "    # Get dimensions from sample data\n",
    "    sample_data = data_objects[0]\n",
    "    node_feature_dim = sample_data.x.shape[1]\n",
    "    \n",
    "    print(f\"Node feature dimension: {node_feature_dim}\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = GraphTransformer(\n",
    "        node_features=node_feature_dim,\n",
    "        hidden_dim=128,\n",
    "        num_heads=8,\n",
    "        num_layers=4,\n",
    "        num_classes=3,  # example: normal, pathological, athletic\n",
    "        dropout=0.1\n",
    "    )\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"\\nModel parameters:\")\n",
    "    print(f\"- Total: {total_params:,}\")\n",
    "    print(f\"- Trainable: {trainable_params:,}\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(sample_data.x, sample_data.edge_index)\n",
    "        print(f\"\\nModel output shape: {output.shape}\")\n",
    "        print(f\"Output (logits): {output.numpy()}\")\n",
    "        \n",
    "        # Convert to probabilities\n",
    "        probs = torch.softmax(output, dim=-1)\n",
    "        print(f\"Probabilities: {probs.numpy()}\")\n",
    "        \n",
    "    print(\"âœ“ GraphTransformer forward pass successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f774f495",
   "metadata": {},
   "source": [
    "## 6. Test Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trc_data is not None and data_objects:\n",
    "    print(\"Testing complete pipeline...\")\n",
    "    \n",
    "    # Process multiple data objects\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    print(f\"Processing {len(data_objects)} data objects...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(data_objects[:5]):  # Test first 5 for speed\n",
    "            output = model(data.x, data.edge_index)\n",
    "            pred_class = torch.argmax(output, dim=-1).item()\n",
    "            confidence = torch.max(torch.softmax(output, dim=-1)).item()\n",
    "            \n",
    "            predictions.append({\n",
    "                'frame_start': data.frame_start,\n",
    "                'frame_end': data.frame_end, \n",
    "                'predicted_class': pred_class,\n",
    "                'confidence': confidence\n",
    "            })\n",
    "            \n",
    "            if i == 0:\n",
    "                print(f\"  Sample {i+1}: frames {data.frame_start}-{data.frame_end}, \"\n",
    "                      f\"class {pred_class}, confidence {confidence:.3f}\")\n",
    "    \n",
    "    print(f\"\\nPipeline Results:\")\n",
    "    print(f\"- Processed {len(predictions)} time windows\")\n",
    "    print(f\"- Predicted classes: {[p['predicted_class'] for p in predictions]}\")\n",
    "    print(f\"- Mean confidence: {np.mean([p['confidence'] for p in predictions]):.3f}\")\n",
    "    \n",
    "    print(\"\\nâœ“ Complete pipeline test successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8915c9",
   "metadata": {},
   "source": [
    "## 7. Visualization Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfbff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trc_data is not None:\n",
    "    print(\"Creating motion visualization...\")\n",
    "    \n",
    "    # Plot trajectory of a few key markers\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle('Motion Capture Data Analysis', fontsize=16)\n",
    "    \n",
    "    # Find some markers to plot\n",
    "    markers_to_plot = []\n",
    "    priority_markers = ['RAnkle', 'LAnkle', 'RKnee', 'LKnee', 'midHip', 'Neck']\n",
    "    \n",
    "    for marker in priority_markers:\n",
    "        if marker in trc_data['joint_names']:\n",
    "            markers_to_plot.append(marker)\n",
    "            if len(markers_to_plot) >= 4:\n",
    "                break\n",
    "    \n",
    "    # If no priority markers found, use first 4 available\n",
    "    if not markers_to_plot:\n",
    "        markers_to_plot = trc_data['joint_names'][:4]\n",
    "    \n",
    "    positions = trc_data['positions']\n",
    "    time = np.arange(len(positions)) / trc_data['frame_rate']\n",
    "    \n",
    "    for i, marker in enumerate(markers_to_plot[:4]):\n",
    "        row, col = i // 2, i % 2\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        marker_idx = trc_data['joint_names'].index(marker)\n",
    "        marker_pos = positions[:, marker_idx, :]\n",
    "        \n",
    "        ax.plot(time, marker_pos[:, 0], 'r-', label='X', alpha=0.7)\n",
    "        ax.plot(time, marker_pos[:, 1], 'g-', label='Y', alpha=0.7) \n",
    "        ax.plot(time, marker_pos[:, 2], 'b-', label='Z', alpha=0.7)\n",
    "        \n",
    "        ax.set_title(f'{marker} Position')\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        ax.set_ylabel('Position (mm)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"âœ“ Plotted trajectories for markers: {markers_to_plot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc804d90",
   "metadata": {},
   "source": [
    "## 8. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7347ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "if trc_data is not None:\n",
    "    print(\"Performance benchmarking...\")\n",
    "    \n",
    "    # Benchmark TRC parsing\n",
    "    start_time = time.time()\n",
    "    parser = TRCParser()\n",
    "    test_data = parser.parse_file(\"/home/funsega/jump.trc\")\n",
    "    parse_time = time.time() - start_time\n",
    "    \n",
    "    # Benchmark graph conversion\n",
    "    start_time = time.time()\n",
    "    converter = MotionGraphConverter()\n",
    "    graph_data = converter.trc_to_pyg_data(test_data, frame_window=10)\n",
    "    convert_time = time.time() - start_time\n",
    "    \n",
    "    # Benchmark model inference\n",
    "    if graph_data:\n",
    "        model.eval()\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            for data in graph_data[:10]:  # Test 10 samples\n",
    "                _ = model(data.x, data.edge_index)\n",
    "        inference_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nPerformance Results:\")\n",
    "        print(f\"- TRC parsing: {parse_time:.3f} seconds\")\n",
    "        print(f\"- Graph conversion: {convert_time:.3f} seconds\")\n",
    "        print(f\"- Model inference (10 samples): {inference_time:.3f} seconds\")\n",
    "        print(f\"- Average inference per sample: {inference_time/10:.4f} seconds\")\n",
    "        \n",
    "        # Calculate throughput\n",
    "        total_frames = len(test_data['positions'])\n",
    "        frames_per_second = total_frames / (parse_time + convert_time + inference_time)\n",
    "        print(f\"- Overall throughput: {frames_per_second:.1f} frames/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283f3f0b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook tested the complete GraphMechanics package functionality:\n",
    "\n",
    "### âœ… Components Tested:\n",
    "1. **TRCParser** - Motion capture file parsing\n",
    "2. **MotionGraphConverter** - Convert motion data to graph format\n",
    "3. **KinematicGraphBuilder** - Build skeletal connectivity graphs\n",
    "4. **GraphTransformer** - Neural network model for motion analysis\n",
    "5. **Complete Pipeline** - End-to-end processing\n",
    "\n",
    "### ðŸ“Š Results:\n",
    "- Successfully processed jump motion capture data\n",
    "- Generated graph representations with proper connectivity\n",
    "- Model inference working correctly\n",
    "- Performance benchmarks completed\n",
    "\n",
    "### ðŸš€ Next Steps:\n",
    "- Train model on labeled motion data\n",
    "- Implement more sophisticated graph features\n",
    "- Add data augmentation techniques\n",
    "- Optimize for real-time processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
